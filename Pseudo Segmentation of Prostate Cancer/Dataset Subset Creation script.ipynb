{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "237fc34f",
   "metadata": {},
   "source": [
    "# About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba799eb",
   "metadata": {},
   "source": [
    "### This notebook is a utility notebook that downloads a zipped subset of the original [`prostate-cancer-grade-assessment`](https://www.kaggle.com/competitions/prostate-cancer-grade-assessment) dataset according to the user's input. This dataset has been hosted on the Kaggle and hence this notebook must be used in the Kaggle environment.\n",
    "\n",
    "#### Steps to get started:\n",
    "1. Click on this link [(click here)](https://www.kaggle.com/competitions/prostate-cancer-grade-assessment) and navigate to the code section.\n",
    "2. Click on `New Notebook` and upload this notebook.\n",
    "3. Run all the cells.\n",
    "4. After a successful run click on the link saying `Download zip File`.\n",
    "\n",
    "> Your subset will be packed in a zip file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b0dad",
   "metadata": {
    "papermill": {
     "duration": 0.004169,
     "end_time": "2022-06-15T18:22:10.069491",
     "exception": false,
     "start_time": "2022-06-15T18:22:10.065322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f171f0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T18:22:10.078721Z",
     "iopub.status.busy": "2022-06-15T18:22:10.077952Z",
     "iopub.status.idle": "2022-06-15T18:22:10.087584Z",
     "shell.execute_reply": "2022-06-15T18:22:10.086680Z"
    },
    "papermill": {
     "duration": 0.018506,
     "end_time": "2022-06-15T18:22:10.090484",
     "exception": false,
     "start_time": "2022-06-15T18:22:10.071978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a4778d",
   "metadata": {},
   "source": [
    "### Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "988a4133",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T18:22:10.097787Z",
     "iopub.status.busy": "2022-06-15T18:22:10.097184Z",
     "iopub.status.idle": "2022-06-15T18:22:10.101683Z",
     "shell.execute_reply": "2022-06-15T18:22:10.101197Z"
    },
    "papermill": {
     "duration": 0.009745,
     "end_time": "2022-06-15T18:22:10.103182",
     "exception": false,
     "start_time": "2022-06-15T18:22:10.093437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants for the Input data directories\n",
    "BASE_DIR = '../input/prostate-cancer-grade-assessment'\n",
    "IMAGES_DIR = os.path.join(BASE_DIR, 'train_images')\n",
    "MASK_DIR = os.path.join(BASE_DIR, 'train_label_masks')\n",
    "\n",
    "# Constants for the output data directories\n",
    "__output_base = './subset'\n",
    "__train_images_subset = './subset/train_images_subset'\n",
    "__train_masks_subset = './subset/train_masks_subset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95157926",
   "metadata": {},
   "source": [
    "### The below utility function is needed, as the authors of this dataset has not provided the masks for all the tiff image slides. Hence, to mitigate any `FileNotFoundErrors` this utility will be useful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e582146",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T18:22:10.109783Z",
     "iopub.status.busy": "2022-06-15T18:22:10.109415Z",
     "iopub.status.idle": "2022-06-15T18:22:10.787299Z",
     "shell.execute_reply": "2022-06-15T18:22:10.786321Z"
    },
    "papermill": {
     "duration": 0.683457,
     "end_time": "2022-06-15T18:22:10.789381",
     "exception": false,
     "start_time": "2022-06-15T18:22:10.105924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_mask_safe_df() -> pd.DataFrame:\n",
    "    \"\"\"Returns a pandas DataFrame object containing valid pairs of slide images and their associated mask images\n",
    "    \n",
    "    Returns:\n",
    "        mask_safe_df: pandas.DataFrame. This dataframe contains information about the images which has a valid \n",
    "        mask associated in the original data.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_df = pd.read_csv('../input/prostate-cancer-grade-assessment/train.csv') # read the original csv file\n",
    "    masks = os.listdir('../input/prostate-cancer-grade-assessment/train_label_masks') # list the files in the mask dir\n",
    "    masks_df = pd.Series(masks).to_frame()\n",
    "    masks_df.columns = ['mask_file_name']\n",
    "    masks_df['image_id'] = masks_df.mask_file_name.apply(lambda x: x.split('_')[0]) # remove '_mask' from the mask_id\n",
    "    train_df = pd.merge(train_df, masks_df, on='image_id', how='outer')\n",
    "    train_df = train_df[~train_df.mask_file_name.isna()] # drop rows whose masks are not present\n",
    "    mask_safe_df = train_df.copy()\n",
    "    mask_safe_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return mask_safe_df\n",
    "\n",
    "mask_safe_df = create_mask_safe_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba51c78f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T18:22:10.795998Z",
     "iopub.status.busy": "2022-06-15T18:22:10.795651Z",
     "iopub.status.idle": "2022-06-15T18:22:10.810107Z",
     "shell.execute_reply": "2022-06-15T18:22:10.809385Z"
    },
    "papermill": {
     "duration": 0.01963,
     "end_time": "2022-06-15T18:22:10.811649",
     "exception": false,
     "start_time": "2022-06-15T18:22:10.792019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_subset(subset_size: float, df: pd.DataFrame, output_filename: str, mode='balanced'):\n",
    "    \"\"\"Generates a subset of the original dataset and packs it in a zip file\n",
    "    \n",
    "    Args:\n",
    "        subset_size: float. Size of the desired subset of the original data in GigaBytes(GB).\n",
    "        df: pandas.DataFrame. A dataframe that contains raw information about the images and their masks.\n",
    "        output_filename: str. filename of the final zipped subset (without '.zip' extension).\n",
    "        mode: One of {\"balanced\", \"random\"}. Default is \"balanced\". Represents the desired distribution of all the\n",
    "        classes in the subset.\n",
    "        - 'balanced': Class distribution will be balanced throughout the subset.\n",
    "        - 'random': Class distribution will be random.\n",
    "        \n",
    "    Raises:\n",
    "        OSError: if the argument `subset_size` is set greater than the size of the original dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    size = 0\n",
    "    for image_id in df['image_id'].values:\n",
    "        size += os.path.getsize(f'{IMAGES_DIR}/{image_id}.tiff')\n",
    "        if (subset_size * 1e+9) <= size:\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        raise OSError(f\"size of the subset should be less than or eqaul to {size / 1e+9} GB\") # 370.181554234 GB == size / 1e+9\n",
    "\n",
    "    if not os.path.exists(__output_base):\n",
    "        os.mkdir(__output_base)\n",
    "    \n",
    "    if not os.path.exists(__train_images_subset):\n",
    "        os.mkdir(__train_images_subset)\n",
    "        \n",
    "    if not os.path.exists(__train_masks_subset):\n",
    "        os.mkdir(__train_masks_subset)\n",
    "        \n",
    "        \n",
    "    size = 0\n",
    "    print(f'Making a {mode} subset')\n",
    "    filenames = []\n",
    "\n",
    "\n",
    "    if mode == 'balanced':\n",
    "        \n",
    "        counter = 0\n",
    "        num_classes = len(df['isup_grade'].unique())\n",
    "        class_wise_images = [list(df['image_id'][df['isup_grade'] == i].values) for i in range(num_classes)]\n",
    "        \n",
    "        while True:\n",
    "            ind = np.random.randint(0, len(class_wise_images[counter]), 1)[0]\n",
    "            \n",
    "            img = f'{IMAGES_DIR}/{class_wise_images[counter][ind]}.tiff'            \n",
    "            mask = f'{MASK_DIR}/{class_wise_images[counter][ind]}_mask.tiff'\n",
    "            \n",
    "            size += os.path.getsize(img)\n",
    "            size += os.path.getsize(mask)\n",
    "            \n",
    "            if size >= subset_size * 1e+9:\n",
    "                break\n",
    "            \n",
    "            shutil.copy2(img, __train_images_subset)\n",
    "            shutil.copy2(mask, __train_masks_subset)\n",
    "            \n",
    "            filenames.append(class_wise_images[counter].pop(ind))\n",
    "            \n",
    "            counter = (counter + 1) % num_classes\n",
    "        \n",
    "    elif mode == 'random':\n",
    "        \n",
    "        class_wise_images = list(df['image_id'].values)\n",
    "        \n",
    "        while True:\n",
    "            ind = np.random.randint(0, len(class_wise_images), 1)[0]\n",
    "            \n",
    "            img = f'{IMAGES_DIR}/{class_wise_images[ind]}.tiff'            \n",
    "            mask = f'{MASK_DIR}/{class_wise_images[ind]}_mask.tiff'\n",
    "            \n",
    "            size += os.path.getsize(img)\n",
    "            size += os.path.getsize(mask)\n",
    "            \n",
    "            if size >= subset_size * 1e+9:\n",
    "                break\n",
    "            \n",
    "            shutil.copy2(img, __train_images_subset)\n",
    "            shutil.copy2(mask, __train_masks_subset)\n",
    "            \n",
    "            filenames.append(class_wise_images.pop(ind))\n",
    "\n",
    "            \n",
    "                    \n",
    "    df_copy = df.copy()\n",
    "    df_copy.set_index('image_id', drop=False, inplace=True)\n",
    "    sliced_df_save = df_copy.loc[filenames]\n",
    "    sliced_df_save.to_csv('./subset/train_subset.csv', index=False, encoding='utf-8')\n",
    "        \n",
    "    shutil.make_archive(output_filename, 'zip', './subset')\n",
    "        \n",
    "    print(f'{output_filename}.zip file created with {len(filenames)} '\n",
    "            'tiff files and corresponding masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3002ee7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T18:22:10.817735Z",
     "iopub.status.busy": "2022-06-15T18:22:10.817410Z",
     "iopub.status.idle": "2022-06-15T18:22:13.395745Z",
     "shell.execute_reply": "2022-06-15T18:22:13.394204Z"
    },
    "papermill": {
     "duration": 2.583861,
     "end_time": "2022-06-15T18:22:13.397982",
     "exception": false,
     "start_time": "2022-06-15T18:22:10.814121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a random subset\n",
      "PANDA_subset.zip file created with 1 tiff files and corresponding masks\n"
     ]
    }
   ],
   "source": [
    "get_subset(0.1, mask_safe_df, 'PANDA_subset', mode='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad444990",
   "metadata": {},
   "source": [
    "Click this link below to download the zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef168e",
   "metadata": {
    "papermill": {
     "duration": 0.00361,
     "end_time": "2022-06-15T18:22:13.405698",
     "exception": false,
     "start_time": "2022-06-15T18:22:13.402088",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a href=\"./PANDA_subset.zip\"> Download zip File </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03cf51de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-15T18:22:13.414809Z",
     "iopub.status.busy": "2022-06-15T18:22:13.414436Z",
     "iopub.status.idle": "2022-06-15T18:22:13.432876Z",
     "shell.execute_reply": "2022-06-15T18:22:13.431655Z"
    },
    "papermill": {
     "duration": 0.0254,
     "end_time": "2022-06-15T18:22:13.434898",
     "exception": false,
     "start_time": "2022-06-15T18:22:13.409498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# shutil.rmtree(\"./subset\")\n",
    "# os.remove(\"./PANDA_subset.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.623326,
   "end_time": "2022-06-15T18:22:14.064037",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-15T18:21:59.440711",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
