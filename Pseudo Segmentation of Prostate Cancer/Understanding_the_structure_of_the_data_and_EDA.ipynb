{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow==2.9.0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\nfrom IPython.display import Image, display\nimport PIL\nPIL.Image.MAX_IMAGE_PIXELS = None\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\n\nimport openslide\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow.keras.utils as ku","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:23.049102Z","iopub.execute_input":"2022-06-14T14:50:23.04958Z","iopub.status.idle":"2022-06-14T14:50:32.362133Z","shell.execute_reply.started":"2022-06-14T14:50:23.049473Z","shell.execute_reply":"2022-06-14T14:50:32.361222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_DIR = '../input/prostate-cancer-grade-assessment'\nIMAGES_DIR = os.path.join(BASE_DIR, 'train_images')\nMASK_DIR = os.path.join(BASE_DIR, 'train_label_masks')","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:32.363716Z","iopub.execute_input":"2022-06-14T14:50:32.36444Z","iopub.status.idle":"2022-06-14T14:50:32.371398Z","shell.execute_reply.started":"2022-06-14T14:50:32.364411Z","shell.execute_reply":"2022-06-14T14:50:32.370534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(os.path.join(BASE_DIR, 'train.csv'))\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:32.372664Z","iopub.execute_input":"2022-06-14T14:50:32.37324Z","iopub.status.idle":"2022-06-14T14:50:32.423915Z","shell.execute_reply.started":"2022-06-14T14:50:32.373204Z","shell.execute_reply":"2022-06-14T14:50:32.423198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_copy = train_data.copy()\ntrain_df_copy['image_id'] = train_df_copy['image_id'] + '.tiff'\ntrain_df_copy = train_df_copy.set_index('image_id')","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:32.426107Z","iopub.execute_input":"2022-06-14T14:50:32.426432Z","iopub.status.idle":"2022-06-14T14:50:32.439833Z","shell.execute_reply.started":"2022-06-14T14:50:32.426403Z","shell.execute_reply":"2022-06-14T14:50:32.439136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class EDAUtilFunctions:\n    \n    def __init__(self, dataframe: pd.DataFrame):\n        self.df = dataframe\n    \n    def count_plot(self, col_names: list):\n        \n        plt.figure(figsize=(8,6), tight_layout=True)\n        colors = sns.color_palette('pastel')\n        \n        for col_name in col_names:\n        \n            if col_name not in self.df.columns:\n                raise KeyError(f'{col_name} should be present in {self.df.columns}')\n\n            \n\n            unique_features, counts = np.unique(self.df[col_name], return_counts=True)\n\n            plt.bar(unique_features, counts, color=colors[:len(unique_features)])\n            plt.xticks(rotation=90)\n            plt.xlabel(col_name)\n            plt.ylabel('Count')\n            plt.title('Count Plot')\n            plt.show()\n    \n    def funnel_plot(self, text: str, values: str):\n        if text not in self.df.columns:\n            raise KeyError(f'{text} should be present in {self.df.columns}')\n        \n        if values not in self.df.columns:\n            raise KeyError(f'{values} should be present in {self.df.columns}')\n        \n        fig = go.Figure(go.Funnelarea(\n        text =self.df[text],\n        values = self.df[values],\n        title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of ISUP_grade Distribution\"}))\n        fig.show()\n    \n    \n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:32.441952Z","iopub.execute_input":"2022-06-14T14:50:32.442655Z","iopub.status.idle":"2022-06-14T14:50:32.452896Z","shell.execute_reply.started":"2022-06-14T14:50:32.442621Z","shell.execute_reply":"2022-06-14T14:50:32.452101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eda_df = EDAUtilFunctions(train_data)\neda_df.count_plot(['data_provider', 'isup_grade', 'gleason_score'])","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:32.454313Z","iopub.execute_input":"2022-06-14T14:50:32.454732Z","iopub.status.idle":"2022-06-14T14:50:33.034997Z","shell.execute_reply.started":"2022-06-14T14:50:32.454685Z","shell.execute_reply":"2022-06-14T14:50:33.034143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# t = np.random.randint(200, 226, (5, 5, 3)).astype(np.uint8) - 255.0\n# print(np.sum(t) / 75)\n# plt.imshow((t + 255).astype(np.uint8))","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:33.03626Z","iopub.execute_input":"2022-06-14T14:50:33.036633Z","iopub.status.idle":"2022-06-14T14:50:33.040116Z","shell.execute_reply.started":"2022-06-14T14:50:33.036597Z","shell.execute_reply":"2022-06-14T14:50:33.039289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TIFFVisualization:\n    \n    @staticmethod\n    def visualize_patch(patch_shape: tuple, n_images: int, pos: tuple, img_dir: str, dft: pd.DataFrame):\n        \n\n        filenames = glob.glob(f'{img_dir}/*.tiff')\n        \n        if len(filenames) is 0:\n            raise RuntimeError(f'{img_dir} should contain tiff encoded images')\n        \n        \n        \n        indices = np.random.randint(0, len(filenames), n_images)\n        \n        fig, axes = plt.subplots(n_images // 3, 3, figsize=(20, 60))\n        for i in range(n_images):\n            key_name = filenames[indices[i]].split('/')[-1]\n            slide = openslide.OpenSlide(filenames[indices[i]])\n            patch = slide.read_region(pos, 2, patch_shape)\n            axes[i // 3][i % 3].imshow(patch)\n            slide.close()       \n            axes[i//3, i%3].axis('off')\n            \n            axes[i//3, i%3].set_title(f'image id: {key_name}\\n ISUP Grade: {dft.loc[key_name].isup_grade}')\n            \n        \n        plt.show()\n    \n    @staticmethod\n    def visualize_masks(n_images: int, mask_dir: str, img_dir: str, dft: pd.DataFrame, \n                        max_size=(400, 400), alpha=0.8):\n        \n        filenames = glob.glob(f'{mask_dir}/*.tiff')\n        \n        if len(filenames) is 0:\n            raise RuntimeError(f'{img_dir} should contain tiff encoded images')\n            \n        indices = np.random.randint(0, len(filenames), n_images)\n        \n        fig, axes = plt.subplots(n_images, 2, figsize=(10, 60))\n        \n        for i in range(n_images):\n            key_name = filenames[indices[i]].split('/')[-1]\n            key_name = key_name.replace('_mask', \"\")\n            train_img = f'{img_dir}/{key_name}'\n            \n            img = openslide.OpenSlide(train_img)\n            mask = openslide.OpenSlide(filenames[indices[i]])\n            \n            img_data = img.read_region((0,0), img.level_count - 1, img.level_dimensions[-1])\n            mask_data = mask.read_region((0,0), mask.level_count - 1, mask.level_dimensions[-1])\n            mask_data = mask_data.split()[0]\n\n            \n            center = dft.loc[key_name]['data_provider']\n            alpha_int = int(round(255*alpha))\n            if center == 'radboud':\n                alpha_content = np.less(mask_data.split()[0], 2).astype('uint8') * alpha_int + (255 - alpha_int)\n            elif center == 'karolinska':\n                alpha_content = np.less(mask_data.split()[0], 1).astype('uint8') * alpha_int + (255 - alpha_int)\n\n            \n\n            alpha_content = PIL.Image.fromarray(alpha_content)\n            preview_palette = np.zeros(shape=768, dtype=int)\n\n            if center == 'radboud':\n                # Mapping: {0: background, 1: stroma, 2: benign epithelium, 3: Gleason 3, 4: Gleason 4, 5: Gleason 5}\n                preview_palette[0:18] = (np.array([0, 0, 0, 0.5, 0.5, 0.5, 0, 1, 0, 1, 1, 0.7, 1, 0.5, 0, 1, 0, 0]) * 255).astype(int)\n            elif center == 'karolinska':\n                # Mapping: {0: background, 1: benign, 2: cancer}\n                preview_palette[0:9] = (np.array([0, 0, 0, 0, 1, 0, 1, 0, 0]) * 255).astype(int)\n\n            mask_data.putpalette(data=preview_palette.tolist())\n            mask_rgb = mask_data.convert(mode='RGB')\n            \n            \n\n            overlayed_image = PIL.Image.composite(image1=img_data, image2=mask_rgb, mask=alpha_content)\n\n            overlayed_image.thumbnail(size=max_size, resample=0)\n            \n            axes[i][1].imshow(overlayed_image)\n            axes[i][0].imshow(img.get_thumbnail(size=max_size))\n            \n            axes[i][0].axis('off')\n            axes[i][1].axis('off')\n\n            \n            axes[i][0].set_title(f'image id: {key_name}\\ncenter: {dft.loc[key_name].data_provider}')\n            axes[i][1].set_title(f' \\n ISUP Grade: {dft.loc[key_name].isup_grade}')\n            \n            img.close()\n            mask.close()\n        \n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:33.041506Z","iopub.execute_input":"2022-06-14T14:50:33.042067Z","iopub.status.idle":"2022-06-14T14:50:33.0668Z","shell.execute_reply.started":"2022-06-14T14:50:33.042026Z","shell.execute_reply":"2022-06-14T14:50:33.065913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TIFFVisualization.visualize_patch((512, 512), 15, np.random.randint(1759, 1800, (2,)), IMAGES_DIR, train_df_copy)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:33.068129Z","iopub.execute_input":"2022-06-14T14:50:33.068529Z","iopub.status.idle":"2022-06-14T14:50:36.065687Z","shell.execute_reply.started":"2022-06-14T14:50:33.06849Z","shell.execute_reply":"2022-06-14T14:50:36.063365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TIFFVisualization.visualize_masks(6, MASK_DIR, IMAGES_DIR, train_df_copy,)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:36.067751Z","iopub.execute_input":"2022-06-14T14:50:36.068865Z","iopub.status.idle":"2022-06-14T14:50:40.087535Z","shell.execute_reply.started":"2022-06-14T14:50:36.068829Z","shell.execute_reply":"2022-06-14T14:50:40.082007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(ku.Sequence):\n    pass\nclass DataGenerator(ku.Sequence):\n    \n    whitelist_tasks = ['classification', 'segmentation',]\n    \n    \n    def __init__(self, \n                 img_dir: str,\n                 df_images: pd.DataFrame, \n                 batch_size: int, \n                 target_size: tuple, \n                 task: str,\n                 mask_dir=None, \n                is_training=True,\n                zoom_range=None,\n                brightness_range=None):\n        \n        self.img_dir = img_dir\n        self.df = df_images.iloc[:5000]\n        self.batch_size = batch_size\n        self.target_size = target_size\n        self.mask_dir = mask_dir\n        self.training = is_training\n        self.zoom_param = zoom_range\n        self.brightness_param = brightness_range\n    \n    \n        if task not in DataGenerator.whitelist_tasks:\n            raise ValueError(f\"task should be one of the {DataGenerator.whitelist_tasks}\")\n        else:\n            self.task = task\n        \n        if mask_dir is not None:\n            train_df = self.df.copy()\n            masks = os.listdir(self.mask_dir)\n            masks_df = pd.Series(masks).to_frame()\n            masks_df.columns = ['mask_file_name']\n            masks_df['image_id'] = masks_df.mask_file_name.apply(lambda x: x.split('_')[0])\n            train_df = pd.merge(train_df, masks_df, on='image_id', how='outer')\n            del masks_df\n            train_df = train_df[~train_df.mask_file_name.isna()]\n            mask_safe_df = train_df.copy()\n            del train_df\n            mask_safe_df = mask_safe_df[mask_safe_df['data_provider'] == 'karolinska']\n            mask_safe_df.reset_index(drop=True, inplace=True)\n            self.mask_safe_df = mask_safe_df\n        \n        if self.task == 'classification':\n            self.indices = range(len(self.df))\n        \n        elif self.task == 'segmentation':\n            self.indices = self.mask_safe_df.index.values\n        \n    \n    def on_epoch_start(self):\n        if self.training:\n            np.random.shuffle(self.indices)\n    \n    def __get_transormed_images(self, image_id: str) -> tf.Tensor:\n        \n        rel_image_path = f'{self.img_dir}/{image_id}.tiff'\n        image = openslide.OpenSlide(rel_image_path)\n        thumbnail = image.get_thumbnail(self.target_size)\n        image.close()\n        \n        img_data = np.array(thumbnail)\n        \n        if self.brightness_param is not None:\n            img_data = tf.keras.preprocessing.image.random_brightness(self.brightness_param)\n        \n        if self.zoom_param is not None:\n            img_data = tf.keras.preprocessing.image.random_zoom(self.zoom_param)\n            \n        \n        img_data = tf.cast(img_data, tf.float32) / 255.0\n        img_data = tf.image.resize(img_data, self.target_size)\n        img_data = tf.expand_dims(img_data, 0)\n        return img_data\n    \n    \n    def __get_overlayed_imgs(self, image_id: str) -> tf.Tensor:\n        base_path = f'{self.img_dir}/{image_id}'\n        mask_path = f'{self.mask_dir}/{image_id}'\n        img = openslide.OpenSlide(f'{base_path}.tiff')\n        mask = openslide.OpenSlide(f'{mask_path}_mask.tiff')\n            \n        img_data = img.read_region((0,0), img.level_count - 1, img.level_dimensions[-1])\n        mask_data = mask.read_region((0,0), mask.level_count - 1, mask.level_dimensions[-1])\n        mask_data = mask_data.split()[0]\n        alpha = 0.8\n        alpha_int = int(round(255*alpha))\n        alpha_content = np.less(mask_data.split()[0], 1).astype('uint8') * alpha_int + (255 - alpha_int)\n        alpha_content = PIL.Image.fromarray(alpha_content)\n        preview_palette = np.zeros(shape=768, dtype=int)\n        \n        preview_palette[0:9] = (np.array([0, 0, 0, 0, 1, 0, 1, 0, 0]) * 255).astype(int)\n\n        mask_data.putpalette(data=preview_palette.tolist())\n        mask_rgb = mask_data.convert(mode='RGB')\n        overlayed_image = PIL.Image.composite(image1=img_data, image2=mask_rgb, mask=alpha_content)\n        overlayed_image.thumbnail(size=self.target_size, resample=0)\n        img_thumbnail = img.get_thumbnail(size=self.target_size)\n        img.close()\n        mask.close()\n        \n        img_thumbnail = tf.cast(np.array(img_thumbnail), tf.float64) / 255.0\n        overlayed_image = tf.cast(np.array(overlayed_image), tf.float64) / 255.0\n        \n        img_thumbnail = tf.image.resize(img_thumbnail, (self.target_size))\n        overlayed_image = tf.image.resize(overlayed_image, (self.target_size))\n        \n        \n        return(img_thumbnail, overlayed_image)\n        \n        \n        \n        \n    def __len__(self):\n        if self.task == 'classification':\n            return len(self.df) // self.batch_size\n        \n        elif self.task == 'segmentation':\n            return (len(self.mask_safe_df) // self.batch_size)\n    \n    def __getitem__(self, idx):\n        batch = self.indices[idx * self.batch_size: (idx + 1) * self.batch_size]\n        \n        if self.task == 'classification':\n            batch_img_ids = self.df['image_id'].iloc[batch].values\n            batch_img_labels = self.df['isup_grade'].iloc[batch].values\n            batch_image_data = [self.__get_transormed_images(file_id) for file_id in batch_img_ids]\n            \n            onehot_batch_labels = ku.to_categorical(batch_img_labels, \n                                                    DataGenerator.__deduce_num_classes(self))\n            \n            \n            return tf.squeeze(tf.stack(batch_image_data), 1), tf.stack(onehot_batch_labels)\n        \n        elif self.task == 'segmentation':\n            try:\n                batch_img_ids = self.mask_safe_df['image_id'].iloc[batch].values\n                batch_overlayed_data = [self.__get_overlayed_imgs(file_id) \n                                                 for file_id in batch_img_ids]\n                img_mask = tf.stack(batch_overlayed_data)\n\n                return img_mask[:, 0, :, :, :], img_mask[:, 1, :, :, :]\n            \n            except Exception as e:\n                pass            \n            \n            \n    @staticmethod\n    def __deduce_num_classes(obj: DataGenerator) -> int:\n        return len(obj.df['isup_grade'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:40.088881Z","iopub.execute_input":"2022-06-14T14:50:40.089383Z","iopub.status.idle":"2022-06-14T14:50:40.120233Z","shell.execute_reply.started":"2022-06-14T14:50:40.089342Z","shell.execute_reply":"2022-06-14T14:50:40.119506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = DataGenerator(IMAGES_DIR,\n                              train_data,\n                              128,\n                              (224, 224), \n                              'classification',\n                              MASK_DIR,\n                             )","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:40.121636Z","iopub.execute_input":"2022-06-14T14:50:40.122195Z","iopub.status.idle":"2022-06-14T14:50:40.167154Z","shell.execute_reply.started":"2022-06-14T14:50:40.122157Z","shell.execute_reply":"2022-06-14T14:50:40.166479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# next(iter(train_datagen))","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:40.168441Z","iopub.execute_input":"2022-06-14T14:50:40.168784Z","iopub.status.idle":"2022-06-14T14:50:40.172722Z","shell.execute_reply.started":"2022-06-14T14:50:40.168749Z","shell.execute_reply":"2022-06-14T14:50:40.171792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classification","metadata":{}},{"cell_type":"code","source":"temp = train_data.copy()\ntemp['image_id'] = temp['image_id'] + '.tiff'\ntemp['isup_grade'] = temp['isup_grade'].astype(str)\ndatagen = ImageDataGenerator(rescale=1./255.0, validation_split=0.2)\ndatagenerator = datagen.flow_from_dataframe(temp,IMAGES_DIR, 'image_id', 'isup_grade',batch_size=2,)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:50:40.174005Z","iopub.execute_input":"2022-06-14T14:50:40.174639Z","iopub.status.idle":"2022-06-14T14:51:08.484565Z","shell.execute_reply.started":"2022-06-14T14:50:40.174602Z","shell.execute_reply":"2022-06-14T14:51:08.483693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.applications.mobilenet_v2.MobileNetV2(weights='imagenet', include_top=False, \n                                                       input_shape=(256, 256, 3))\ndef build_model(pre_trained_model: tf.keras.Model) -> tf.keras.Model:\n    for layer in pre_trained_model.layers:\n        layer.trainable=False\n    \n    \n    \n    x = pre_trained_model.outputs[0]\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dense(512, activation='relu')(x)\n    outputs = layers.Dense(6, activation='softmax')(x)\n    \n    model = tf.keras.Model(inputs=[pre_trained_model.inputs], outputs=[outputs], name='test_model')\n    return model\n\nmodel = build_model(model)\n\nMETRICS = [\n      tf.keras.metrics.TruePositives(name='tp'),\n      tf.keras.metrics.FalsePositives(name='fp'),\n      tf.keras.metrics.TrueNegatives(name='tn'),\n      tf.keras.metrics.FalseNegatives(name='fn'), \n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),\n      tf.keras.metrics.AUC(name='auc'),\n      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n]\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='recall', patience=2, mode='max', restore_best_weights=True, verbose=1\n)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n             loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n             metrics=METRICS)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T14:51:08.485971Z","iopub.execute_input":"2022-06-14T14:51:08.486558Z","iopub.status.idle":"2022-06-14T14:51:12.718622Z","shell.execute_reply.started":"2022-06-14T14:51:08.486517Z","shell.execute_reply":"2022-06-14T14:51:12.717843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(datagenerator, epochs=100, verbose=1, callbacks=[early_stopping],)","metadata":{"execution":{"iopub.status.busy":"2022-06-14T06:43:39.521257Z","iopub.execute_input":"2022-06-14T06:43:39.521615Z","iopub.status.idle":"2022-06-14T06:51:08.569375Z","shell.execute_reply.started":"2022-06-14T06:43:39.521582Z","shell.execute_reply":"2022-06-14T06:51:08.568379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Segmentation","metadata":{}},{"cell_type":"code","source":"def build_model():\n  inputs = layers.Input((224, 224, 3))\n\n  conv1 = layers.Conv2D(2, 32, 2, padding='same', activation='relu')(inputs)\n  conv2 = layers.Conv2D(4, 32, 2, padding='same', activation='relu')(conv1)\n  conv3 = layers.Conv2D(8, 32, 2, padding='same', activation='relu')(conv2)\n  conv4 = layers.Conv2D(16, 32, 2, padding='same', activation='relu')(conv3)\n  conv5 = layers.Conv2D(32, 32, 2, padding='same', activation='relu')(conv4)\n\n  deconv1 = layers.Conv2DTranspose(32, 32, 1, padding='same')(conv5)\n  concat = layers.Concatenate()([conv5, deconv1])\n  deconv2 = layers.Conv2DTranspose(16, 32, 2, padding='same')(concat)\n  concat = layers.Concatenate()([conv4, deconv2])\n  deconv3 = layers.Conv2DTranspose(8, 32, 2, padding='same')(concat)\n  concat = layers.Concatenate()([conv3, deconv3])\n  deconv4 = layers.Conv2DTranspose(4, 32, 2, padding='same')(concat)\n  concat = layers.Concatenate()([conv2, deconv4])\n  deconv5 = layers.Conv2DTranspose(2, 32, 2, padding='same')(concat)\n  concat = layers.Concatenate()([conv1, deconv5])\n  deconv6 = layers.Conv2DTranspose(1, 32, 2, padding='same')(concat)\n  concat = layers.Concatenate()([inputs, deconv6])\n  deconv6 = layers.Conv2DTranspose(3, 32, 1, padding='same', activation='linear')(concat)\n\n\n\n  model = tf.keras.Model(inputs=[inputs], outputs=[deconv6], name='auto_encoders_for_noise_removal')\n\n  return model\n\nmodel = build_model()\n\nprint(model.summary())\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(),\n              loss=tf.keras.losses.Huber(),\n              metrics='mae')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-14T05:31:32.975813Z","iopub.execute_input":"2022-06-14T05:31:32.976676Z","iopub.status.idle":"2022-06-14T05:31:33.18074Z","shell.execute_reply.started":"2022-06-14T05:31:32.976633Z","shell.execute_reply":"2022-06-14T05:31:33.179579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DisplayCallback(tf.keras.callbacks.Callback):\n      def on_epoch_end(self, epoch, logs=None):\n        clear_output(wait=True)\n        show_predictions()\n        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))","metadata":{"execution":{"iopub.status.busy":"2022-06-14T05:31:33.664363Z","iopub.execute_input":"2022-06-14T05:31:33.664864Z","iopub.status.idle":"2022-06-14T05:31:33.670994Z","shell.execute_reply.started":"2022-06-14T05:31:33.664829Z","shell.execute_reply":"2022-06-14T05:31:33.67008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_history = model.fit(train_datagen, epochs=50,\n                          callbacks=[DisplayCallback()])","metadata":{"execution":{"iopub.status.busy":"2022-06-14T05:31:34.138592Z","iopub.execute_input":"2022-06-14T05:31:34.139079Z","iopub.status.idle":"2022-06-14T05:36:45.996276Z","shell.execute_reply.started":"2022-06-14T05:31:34.139044Z","shell.execute_reply":"2022-06-14T05:36:45.995134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}